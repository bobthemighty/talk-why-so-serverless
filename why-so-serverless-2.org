# Why So Serverless?

---
class: compact
# Who am I?

My name is Bob and I'm a software architect and craftsman.

---
class: compact
# Who am I?

I wrote a book for O'Reilly on application architecture in Python: http://github.com/cosmicpython

I have strong opinions about things: http://twitter.com/bobthemighty

I always stick slides up on github, like this: http://github.com/bobthemighty/why-so-serverless

---
# Why so Serverless

???
The title of my talk is "why so serverless", which is a great pun, I think, though I didn't come up with it, and this talk is a small act of rebellion. I've been working at Cazoo for the last few months, and I'm averaging one talk or podcast per month, and _everyone_ wants to talk about serverless. And I'm okay with that, I like talking about serverless, I like talking about technology generally, but I want to talk about something more abstract today, which is software architecture,  how we make decisions, and how that led us to adopt serverless at Cazoo.
  So if you came here specifically to hear all about AWS Lambda, and now you're super disappointed, I'm sorry. The exits are over there, and I'm not going to judge you if you slip out, but there's another talk after this one which probably _will_ be all about lambda and stuff, and also there's pizza, so ... up to you.
---
# Architect (noun, from the Greek architekton; lit. Master Builder)

???
Software architects spend a lot of time thinking about what software architecture _is_. Partly that's because we need to fiund novel ways to justify our pay scales, but it's also because it's a tricky question to answer.
  The word comes from the Greek 'architekton' which literally means "master builder", and the architetekton was like a combination of foreman, architect, and gaffer. His job was to run the building site, applying his years of experience to make sure everything was running smoothly.

---
class: img-full

TODO: Jumbled architecture pic

???
Otherwise what happens is that all your engineers disappear into their own bubbles and get swept away by the love of their craft and you end up with this... weird looking thing. Somebody has to make some choices that apply across the board and help define some standards so that everything fits.

---
class: img-full
TODO: Channel Tunnel pic

???
Some poor individual had to perform this role on the Channel Tunnel, right? Because when you've got engineers starting off from opposite sides of the channel, speaking different languages, you need to make sure that they actually meet one another in the middle, and that the tunnels are the same diameter, and so on.

---
class: img-class
TODO: Zen pic

???
Without getting all philosophical about it, I think that the purpose of an architect is to find harmony and balance.

---

class: img-full
TODO: matrix-pic

???
Sometimes late at night I like to watch the logs and metrics flowing past, and see how the system is operating in production. When a system is working _well_ you can watch each part doing its job reliably and smooothly, over and over

---

class: img-full
TODO: Watch gears

???
A tiny cog in a vast and incomprehensible machine. Often software systems get so large that we can't hold the entire thing in our heads any more, but by observing its outputs, we can still get a sense of how it fits together. Harmony is the aesthetic sense that a system is well constructed, and that each part supports the others, like the gears of a watch.

---

class: img-full
TODO: evolution

???
But "well constructed" is a relative term, it depends entirely on the context. The choices that we make for a web form, used by one guy named David on a freezing industrial estate in Bangor, are different from the choices we made for an algorithmic trading system, running on a subterranean mesh of servers with their own fibre-optic network connectivity.
The job of an architect, then, is to help technology teams make choices that are well-adapted to the context, and that are mututally reinforcing, not fighting against one another.

---

# Wut

???
I told you this wasn't going to be about lambda. Like, I fricking warned you.

---
class: title

# Wut even is Serverless?

???
Okay, enough of the high-faltuting handwavey crap. Let's get down to brass tacks. What even is Serverless?

---

class: img-caption

# The Ascent of Bob

TODO: timeline

???

So this is a quick summary of my journey toward serverless architectures. In my first job, I worked for a startup on an industrial estate in Duckmanton, which is an inbred shithole of a village next to Junction 11 of the M1 motorway. We built a content management system that let people design their own websites, and the server was literally underneath the boss's desk. It was a pentium 3, I think, with an ISDN modem that had like 100 kilobytes/sec upstream rate and we served customer sites off this one machine with no backups that also hosted our databases, which were MS Access, and our source code, which wasn't in a version control system because what even _is_ that?
  My next job was for a company that ran sales and management training for car dealerships, and now the server was in a _cupboard_ so it was a bit more serverless because at least I didn't accidentally kick the server sometimes on my way past and I'm fairly sure that we had more than one of them, because it was quite a big cupboard. If we needed a new server, it would probably have taken months to provision.
  I worked for Pipex for a bit, running their Windows Web Hosting team and, as you might imagine being n ISP, they had a _lot_ of servers, but they were further away in a data center, managed by a separate team of ultra-nerds. We served about 10,000 customer websites on each IIS server, and spinning up a new one, plugging it in etc, would take a few weeks.
  Around 2008 I was hosting systems with Rackspace, who offered an amazing managed service where they would look after your servers for you and help with backups and do monitoring and so on. At this point in time we could get a new server in about a week.
  In 2015 I started using AWS properly, and with EC2 autoscaling and infrastructure as code we drove down the time to provision to around two minutes. There's a _lot_ of hard work to make that happen, but it's still amazing to me, an entire server, provisioned just the way we want it in two minutes.
  Lastly, of course, I'm now working at Cazoo where we have no servers at all, just these _lambda_ things, and they take under a second to spin up on demand as our traffic shifts throughout the day.
At each point in this journey, the servers became physically further away, and conceptually further away. In my first job, I had to copy files over to the server and then go and mess around with IIS settings to make the website appear. Over time, more and more of that work became automated and abstracted. At Cazoo, our deployments are the result of a computer program. We specify in code the amount of resource that we want, and it appears, as though by magic.
  
---
class: img-caption

# Serverless is a Doctrine

TODO: Wardley map of serverless

???
This is a Wardley map, it's a way of visualising a high-level depiciton of a situation and how you expect it to change over time. The guy who came up with these is Simon Wardley, who was in charge of ""cloud" at Canonical around the time that Ubuntu became ubiquitous. He talks a lot about how we produce strategy, and one of his terms is Doctrine. A Doctrine is a set of universal principles that we can apply to situations to help up come up with answers.
The serverless doctrine is this: I don't want to do work if I can pay someone else to do it for me, because that frees me up to focus on the important things.

---
class: img-caption

# Product-Alignment Matrix

???

This is a product alignment matrix. I was taught to use these when I was hosting on Rackspace, by a friend and mentor. The idea is that we plot out the stuff that we do as an organisations in this two dimensional space. 

---
class: img-full

TODO: PA Matrix highlight right
On the X axis is _mission critical_. On the right is the stuff that we have to do, whether we like it or not. On the left is stuff that we could stop doing, and maybe nobody would care.

---
class: img-full

TODO: Product alignment highlight upper
On the Y axis is business differentiation - at the top are the things that nobody else does, that makes your business a unique and special snowflake. At the bottom are the things that everybody does.

---
class: img-full

TODO: Product alignment highlight buy build stop partner

???

We can use this to inform our technology choices. Stuff that is critical and boring, we should buy off the shelf. For example, Stripe. Don't build your own credit card processor, it's boring and critical. If you get it wrong, it's really expensive, and nobody uses your website for its fantastic card payment systems.

Stuff that is differentiating but not critical, we should consider _partnering_. For exmaple, maybe we could have an app where you swipe left or right on different cars and then we make some recommendations about what kind of vehicle you should buy. It would be a bit of harmless fun that maybe drives some extra traffic to the site. Outsource it, it's fluff.

Stuff that's not differentiating OR mission critical is in the lower left, and we should just _stop_ doing that. For example, we've had a few conversations about voucher codes, but we dont' feel that the revenue will justify it. It's not exciting enough to make people come to Cazoo, and it's not profitable enough that we _have_ to do it.

That leaves this space in the upper right. This is the stuff you should build. This is the area where you need to write clean code with fancy architecture and work hard on making it _right_. This is your core domain.

---

class: img-full

TODO: Product alignment

???

Let's try this out. Things we do as an organisation. Well we take payments. We've talked about that one already. That goes in the lower right, as do a bunch of other things. "Add to cart", "user analytics", and 90% of running an e-commerce system: it's all critical to us selling cars on the internet, but completely boring and the same as amazon, or MADE.com, or Ocado.

---
class: img-full

TODO: Product alignment

???

Delivering cars to your house? That's upper right. Autotrader won't do that, nor will the dealership at the end of your road. Refurbishing thousands of cars every month? Upper right. Buying thousands of cars at auction, with machine learning to work out how much to spend on them? Upper right. This stuff is critical, and unique to us as a business. It gives us an edge over our competitors.

---
class: img-full

TODO: Product alignment

???

What about "hosting a website"? Does that give us an edge? I mean it's critical, sure, but it's totally 100% boring. What about patching servers?  Continuous integration? Running a source control system? What about monitoring? What about backups?

In my last job, the EC2 hosted one, we ran a bunch of elasticsearch clusters, and a grafana instance with Riemann, and a docker cluster using Hashicorp nomad, and a distributed config management system with Consul, and a clever caching and routing layer with HAProxy.

All of it is bottom right. All the devops tooling you're so proud of? Bottom right. Boring but necessary. In 2020, if you're thinking of deploying your own Kubernetes cluster, then you're living the bottom-right dream.

---
class: img-full

Think Service-ful

???

There's an on-going war in the serverless community about what to call ourselves. A lot of Very Smart People who are Extremly Online don't like the term serverless because it forcuses on the wrong thing. The point of serverless _isn't_ that we don't have any servers - that's a necessary component, but it's a side-effect of the doctrin. Instead we should think about _services_. We want to rely on third party services for as much of the heavy lifting as we can. Function-as-a-service, like Lambda, is one manifestation of this Doctrine. With Lambda I just write my code, and somebody else figures out how to run it for me. There's entire classes of tools I no longer need to think about. Log aggregation? Cloudwatch. Routing and service discovery? API Gateway. Message queues? SQS, EventBridge. File storage? S3. All of these problems are hard, and all of them are now solved for 99% of production workloads.

---

class: img-full

TODO: Old context diagram?

???
This is a context diagram I made of Cazoo a while ago when we were discussing micro-frontends. We see three systems that we want to build, the ones in dark blue. Each provides some small bit of functionality for our customer-facing website: checkouts and payments, editorial content like car reviews or that irritatingly twee prose you find on the back of soft drink bottles, and product search and browse. Each of those three systems is backed by an external service: a headless CMS, a headless e-commerce platform, and a headless search engine. We're just providing the glue, and customising these generic components to make sense in our domain. I think that, increasingly, your architectures will look like this because the alternative is that you build all this _Stuff_ that is bottom right and boring and it will take you years just to provide the basics, while your competitors blow right past you.
Each of those three systems is a bunch of lambda functions, and S3 buckets, and maybe a DynamoDB table. There's no servers to run, no firewalls to configure. The source code and CI process are in Gitlab. The caching and routing layer is in Cloudflare. The monitoring comes from Honeycomb. It's services all the way down. My prediction for the next few years is that we'll see more of this kind of commodification, for ever larger chunks of your architectures. 

---

class: img-full

TODO: Lambda diagram

???
There are entire classes of application that we'll create without any code at all: when I upload a file to this s3 bucket, create a notification, run a lambda function that extracts text from the file, put it on another queue, perform sentiment analysis, if the sentiment is negative send me a slack notification. I'll be able to create entire systems like this using off-the-shelf components and some configuration.

---

class: img-full

TODO: Y U NO SERVERLESS?

???
I hope I've stated my case strongly enough, but I want to quickly end by talking about the downsides, the reasons why you might feel you can't use serverless architectures.

---

1. Serverless is expensive

??? 
The internet is full of horrifying stories about some poor dude that hooked up a lambda function to the internet and came back the next day to find he'd racked up a bill for a hundred trillion pounds. I was kinda worried about this one myself.

---

1. Actually Serverless is Metered

???
IT turns out not to be a problem, in my case at least. For example we now run a fairly busy e-commerce site with about 20 thousand unique visitors each day. We have a whole bunch of crazy analytics workloads that do horrible things, and some back office tools for arranging deliveries and that kind of thing. We spend, across all our environments, dev, test, and production, about $4.50 a day on Lambda.
A few months ago I was looking at the logs and I found that the data team had done something _insane_ which is what data teams are _for_ of course, and they'd run 20,000 lambda invocations in a few minutes and they'd all run for ten minutes at a time or something. I was about to storm downstairs and be all like "you guys are racking up huge bills, you're bad people, and you should feel bad" and then I did the maths, and I realised they'd spent 17p on compute time.
So _Firstly_ it turns out that lambda is often not as expensive as you might expect, but secondly, how many of you can calculate - to the penny - how much it costs you to run a particular application? That kind of insight is enormously powerful, and it's only really possible with the pay-per-use model of serviceful architectures.

---

2.  
